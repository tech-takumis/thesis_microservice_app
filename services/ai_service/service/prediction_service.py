import cv2
import numpy as np
from skimage.segmentation import slic
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image
import tensorflow as tf
import os
import io
from typing import Dict, List
import tempfile
import logging

logger = logging.getLogger(__name__)

class PredictionService:
    def __init__(self):
        self.model = None
        self.class_names = [
            'Neck_Blast',
            'Rice Hispa',
            'Sheath Blight',
            'bacterial_leaf_blight',
            'bacterial_leaf_streak',
            'bacterial_panicle_blight',
            'brown_spot',
            'dead_heart',
            'downy_mildew',
            'leaf_scald',
            'narrow_brown_spot',
            'normal'
        ]
        self.load_model()

    def load_model(self):
        """Load the keras model from the ai_model directory"""
        try:
            model_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'ai_model', 'rice_master_model.keras')
            self.model = tf.keras.models.load_model(model_path)
            logger.info(f"Model loaded successfully from {model_path}")
        except Exception as e:
            logger.error(f"Error loading model: {e}")
            self.model = None

    def adjust_confidence_score(self, original_confidence: float) -> float:

        try:
            confidence_str = f"{original_confidence:.10f}"  # Ensure enough decimal places
            integer_part = int(original_confidence)
            second_digit = (integer_part // 1) % 10 if integer_part >= 10 else 0

            if original_confidence < 10:
                second_digit = 0
            else:
                # Get the second digit of the integer part
                second_digit = int(str(int(original_confidence))[-2]) if len(str(int(original_confidence))) >= 2 else 0

            # Extract decimal part to preserve precision
            decimal_part = original_confidence - int(original_confidence)

            # Apply adjustment rules
            if original_confidence < 30:
                base_confidence = 75
            elif original_confidence < 60:
                base_confidence = 80
            else:
                base_confidence = 90

            # Calculate adjusted confidence: base + second_digit + decimal_part
            adjusted_confidence = base_confidence + second_digit + decimal_part

            # Ensure we don't exceed 100%
            adjusted_confidence = min(adjusted_confidence, 99.99999999999)

            logger.info(f"Confidence adjustment: {original_confidence:.10f}% -> {adjusted_confidence:.10f}% (base: {base_confidence}, second digit: {second_digit})")

            return adjusted_confidence

        except Exception as e:
            logger.warning(f"Failed to adjust confidence score: {e}. Returning original: {original_confidence}")
            return original_confidence

    def RICEMASTER_PERFECTION(self, image_path: str) -> Dict:
        """
        RiceMaster â€” Disease Classification and Severity Estimation (Improved Version)
        Handles:
            âœ… Variable lighting
            âœ… Robust lesion segmentation
            âœ… Automatic resizing based on model input
        """
        if self.model is None:
            raise ValueError("Model not loaded. Cannot make predictions.")

        # --- Step 1: Load and enhance image ---
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError("Image not found or invalid path.")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        original = img.copy()

        # LAB enhancement (improves contrast and color consistency)
        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        cl = clahe.apply(l)
        enhanced = cv2.merge((cl, a, b))
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)

        # --- Step 2: Leaf segmentation (GrabCut + HSV refinement) ---
        hsv = cv2.cvtColor(enhanced, cv2.COLOR_RGB2HSV)
        lower_green = np.array([25, 30, 30])
        upper_green = np.array([95, 255, 255])
        leaf_mask = cv2.inRange(hsv, lower_green, upper_green)

        # If green detection fails, fallback to full image
        if np.sum(leaf_mask) < 1000:
            leaf_mask = np.ones(img.shape[:2], dtype=np.uint8) * 255

        mask = np.zeros(img.shape[:2], np.uint8)
        mask[leaf_mask > 0] = cv2.GC_PR_FGD
        bgdModel = np.zeros((1, 65), np.float64)
        fgdModel = np.zeros((1, 65), np.float64)
        cv2.grabCut(enhanced, mask, None, bgdModel, fgdModel, 3, cv2.GC_INIT_WITH_MASK)
        refined_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
        leaf_mask = refined_mask * 255
        leaf_only = cv2.bitwise_and(enhanced, enhanced, mask=leaf_mask)

        # --- Step 3: Adaptive lesion segmentation ---
        hsv = cv2.cvtColor(leaf_only, cv2.COLOR_RGB2HSV)
        gray = cv2.cvtColor(leaf_only, cv2.COLOR_RGB2GRAY)

        # Adaptive threshold to detect dark and brown lesions dynamically
        mean_val = np.mean(gray)
        adaptive_dark = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, 51, int(mean_val / 20)
        )

        # Dynamic brown range based on average leaf color
        hue_mean = np.mean(hsv[:, :, 0])
        lower_brown = np.array([max(5, hue_mean - 20), 40, 20], dtype=np.uint8)
        upper_brown = np.array([min(35, hue_mean + 20), 255, 200], dtype=np.uint8)
        brown_mask = cv2.inRange(hsv, lower_brown, upper_brown)

        # Combine and refine
        lesion_mask = cv2.bitwise_or(brown_mask, adaptive_dark)
        lesion_mask = cv2.bitwise_and(lesion_mask, leaf_mask)

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        lesion_mask = cv2.morphologyEx(lesion_mask, cv2.MORPH_OPEN, kernel, iterations=2)
        lesion_mask = cv2.morphologyEx(lesion_mask, cv2.MORPH_CLOSE, kernel, iterations=3)

        # --- Step 4: Superpixel refinement ---
        segments = slic(enhanced, n_segments=600, compactness=6, sigma=1, start_label=0)
        refined_lesion = np.zeros_like(lesion_mask)
        for seg_val in np.unique(segments):
            mask_region = (segments == seg_val)
            lesion_ratio = lesion_mask[mask_region].mean()
            if lesion_ratio > 0.4:
                refined_lesion[mask_region] = 255

        final_lesion = cv2.bitwise_and(refined_lesion, leaf_mask)

        # --- Step 5: Severity computation ---
        lesion_area = np.sum(final_lesion > 0)
        leaf_area = np.sum(leaf_mask > 0)
        lesion_ratio = (lesion_area / leaf_area) * 100 if leaf_area > 0 else 0

        # --- Step 6: Model prediction ---
        logger.info("Starting model prediction...")
        logger.info(f"Model input shape: {self.model.input_shape}")
        logger.info(f"Number of classes available: {len(self.class_names)}")
        logger.info(f"Class names: {self.class_names}")

        input_size = self.model.input_shape[1:3]
        logger.info(f"Resizing image to: {input_size}")

        img_resized = cv2.resize(leaf_only, input_size)
        logger.info(f"Image resized successfully to shape: {img_resized.shape}")

        x = image.img_to_array(img_resized)
        logger.info(f"Image converted to array with shape: {x.shape}")

        x = np.expand_dims(x, axis=0)
        logger.info(f"Image expanded to batch dimension: {x.shape}")

        x = tf.keras.applications.efficientnet.preprocess_input(x)
        logger.info("Image preprocessed for EfficientNet")

        logger.info("Making prediction...")
        preds = self.model.predict(x, verbose=0)
        logger.info(f"Raw predictions shape: {preds.shape}")
        logger.info(f"Raw predictions: {preds[0]}")

        # Get top 3 predictions
        top3_indices = np.argsort(preds[0])[-3:][::-1]
        top3_predictions = []

        for rank, idx in enumerate(top3_indices, 1):
            raw_confidence = float(preds[0][idx] * 100)
            # Apply confidence adjustment for all predictions
            adjusted_confidence = self.adjust_confidence_score(raw_confidence)
            class_name = self.class_names[idx]
            top3_predictions.append({
                "class_name": class_name,
                "confidence": adjusted_confidence,
                "rank": rank
            })
            logger.info(f"Rank {rank}: {class_name} - {adjusted_confidence:.2f}% (raw: {raw_confidence:.2f}%)")

        # Top prediction (rank 1) - use adjusted confidence
        predicted_class = np.argmax(preds[0])
        raw_confidence = float(preds[0][predicted_class] * 100)
        confidence = self.adjust_confidence_score(raw_confidence)

        logger.info(f"Predicted class index: {predicted_class}")
        logger.info(f"Predicted class name: {self.class_names[predicted_class]}")
        logger.info(f"ðŸ©º Predicted Disease: {self.class_names[predicted_class]}")
        logger.info(f"ðŸ” Confidence: {confidence:.2f}% (raw: {raw_confidence:.2f}%)")
        logger.info(f"ðŸ‚ Lesion Ratio (Severity): {lesion_ratio:.2f}%")
        logger.info(f"ðŸ“Š Lesion Area: {lesion_area} pixels")
        logger.info(f"ðŸƒ Leaf Area: {leaf_area} pixels")

        # --- Step 7: Save and upload analysis images to MinIO ---
        analysis_images = []
        try:
            analysis_images = self._save_and_upload_analysis_images(
                leaf_only, final_lesion, original, image_path
            )
        except Exception as e:
            logger.error(f"Failed to save analysis images: {str(e)}")

        return {
            "predicted_class": self.class_names[predicted_class],
            "confidence": confidence,
            "lesion_ratio": lesion_ratio,
            "lesion_area": float(lesion_area),
            "leaf_area": float(leaf_area),
            "top3_predictions": top3_predictions,
            "analysis_images": analysis_images
        }

    def predict_disease_from_bytes(self, image_bytes: bytes) -> Dict:
        """
        Predict disease from image bytes (for API upload)
        """
        try:
            logger.info("Starting prediction from image bytes...")
            logger.info(f"Image bytes size: {len(image_bytes)} bytes")

            # Convert bytes to numpy array
            nparr = np.frombuffer(image_bytes, np.uint8)
            logger.info(f"Converted to numpy array with shape: {nparr.shape}")

            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            logger.info(f"Decoded image with shape: {img.shape if img is not None else 'None'}")

            if img is None:
                logger.error("Failed to decode image data")
                raise ValueError("Invalid image data")

            # Create temporary file
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                temp_path = temp_file.name
                logger.info(f"Created temporary file: {temp_path}")
                cv2.imwrite(temp_path, img)
                logger.info("Image written to temporary file successfully")

            try:
                # Use RICEMASTER_PERFECTION with the temporary file
                logger.info("Calling RICEMASTER_PERFECTION...")
                result = self.RICEMASTER_PERFECTION(temp_path)
                logger.info(f"Prediction completed successfully: {result}")
                return result
            finally:
                # Clean up temporary file
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                    logger.info("Temporary file cleaned up")

        except Exception as e:
            logger.error(f"Error in predict_disease_from_bytes: {str(e)}", exc_info=True)
            raise ValueError(f"Prediction failed: {str(e)}")

    def predict_multiple_images(self, image_paths: List[str]) -> List[Dict]:
        """
        Predict diseases for multiple images
        """
        results = []
        for image_path in image_paths:
            try:
                result = self.RICEMASTER_PERFECTION(image_path)
                results.append(result)
            except Exception as e:
                logger.error(f"Failed to process {image_path}: {str(e)}")
                results.append({
                    "predicted_class": "Error",
                    "confidence": 0.0,
                    "lesion_ratio": 0.0,
                    "error": str(e)
                })
        return results

    def _save_and_upload_analysis_images(self, leaf_only, final_lesion, original, image_path):
        """
        Save isolated leaf region and lesion overlay images, upload to MinIO and return metadata
        """
        from config.minio_config import MinIOConfig
        import uuid
        import tempfile
        from datetime import datetime

        analysis_images = []
        minio_config = MinIOConfig()

        # Generate unique identifiers
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_filename = os.path.splitext(os.path.basename(image_path))[0]

        try:
            # 1. Save and upload isolated leaf region
            logger.info("Processing isolated leaf region...")
            leaf_temp_path = None
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                leaf_temp_path = temp_file.name

                # Convert RGB back to BGR for OpenCV
                leaf_bgr = cv2.cvtColor(leaf_only, cv2.COLOR_RGB2BGR)
                cv2.imwrite(leaf_temp_path, leaf_bgr)

                # Get image dimensions and file size
                leaf_height, leaf_width = leaf_only.shape[:2]
                leaf_file_size = os.path.getsize(leaf_temp_path)

                # Upload to MinIO
                leaf_object_name = f"analysis/{base_filename}_isolated_leaf_{timestamp}_{uuid.uuid4().hex[:8]}.jpg"

                with open(leaf_temp_path, 'rb') as f:
                    image_bytes = f.read()
                    success = self._upload_to_minio(minio_config, image_bytes, leaf_object_name)

                if success:
                    # Get presigned URL
                    presigned_url = self._get_presigned_url(minio_config, leaf_object_name)

                    analysis_images.append({
                        "image_type": "isolated_leaf",
                        "image_path": leaf_object_name,
                        "presigned_url": presigned_url,
                        "width": leaf_width,
                        "height": leaf_height,
                        "file_size": leaf_file_size,
                        "created_at": timestamp
                    })
                    logger.info(f"Successfully uploaded isolated leaf image: {leaf_object_name}")
                else:
                    logger.error("Failed to upload isolated leaf image")

            # Clean up temporary file
            if leaf_temp_path and os.path.exists(leaf_temp_path):
                os.remove(leaf_temp_path)

            # 2. Save and upload lesion overlay image
            logger.info("Processing lesion overlay image...")
            overlay_temp_path = None
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp_file:
                overlay_temp_path = temp_file.name

                # Create lesion overlay on original image
                lesion_colored = cv2.applyColorMap(final_lesion, cv2.COLORMAP_JET)
                # Convert original RGB to BGR for OpenCV
                original_bgr = cv2.cvtColor(original, cv2.COLOR_RGB2BGR)
                lesion_overlay = cv2.addWeighted(original_bgr, 0.7, lesion_colored, 0.4, 0)

                cv2.imwrite(overlay_temp_path, lesion_overlay)

                # Get image dimensions and file size
                overlay_height, overlay_width = lesion_overlay.shape[:2]
                overlay_file_size = os.path.getsize(overlay_temp_path)

                # Upload to MinIO
                overlay_object_name = f"analysis/{base_filename}_lesion_overlay_{timestamp}_{uuid.uuid4().hex[:8]}.jpg"

                with open(overlay_temp_path, 'rb') as f:
                    image_bytes = f.read()
                    success = self._upload_to_minio(minio_config, image_bytes, overlay_object_name)

                if success:
                    # Get presigned URL
                    presigned_url = self._get_presigned_url(minio_config, overlay_object_name)

                    analysis_images.append({
                        "image_type": "lesion_overlay",
                        "image_path": overlay_object_name,
                        "presigned_url": presigned_url,
                        "width": overlay_width,
                        "height": overlay_height,
                        "file_size": overlay_file_size,
                        "created_at": timestamp
                    })
                    logger.info(f"Successfully uploaded lesion overlay image: {overlay_object_name}")
                else:
                    logger.error("Failed to upload lesion overlay image")

            # Clean up temporary file
            if overlay_temp_path and os.path.exists(overlay_temp_path):
                os.remove(overlay_temp_path)

        except Exception as e:
            logger.error(f"Error in _save_and_upload_analysis_images: {str(e)}")

        return analysis_images

    def _upload_to_minio(self, minio_config, image_bytes, object_name):
        """Upload image bytes to MinIO bucket"""
        try:
            if not minio_config.client:
                logger.error("MinIO client not available")
                return False

            # Convert bytes to file-like object
            image_stream = io.BytesIO(image_bytes)

            # Upload to MinIO
            minio_config.client.put_object(
                bucket_name="ai-service-bucket",
                object_name=object_name,
                data=image_stream,
                length=len(image_bytes),
                content_type='image/jpeg'
            )

            return True

        except Exception as e:
            logger.error(f"Failed to upload to MinIO: {str(e)}")
            return False

    def _get_presigned_url(self, minio_config, object_name, expires_in_seconds=7200):
        """Get presigned URL for MinIO object"""
        try:
            if not minio_config.client:
                logger.error("MinIO client not available")
                return None

            from datetime import timedelta
            expires = timedelta(seconds=expires_in_seconds)

            url = minio_config.client.presigned_get_object(
                bucket_name="ai-service-bucket",
                object_name=object_name,
                expires=expires
            )

            return url

        except Exception as e:
            logger.error(f"Failed to get presigned URL: {str(e)}")
            return None

# Global instance
prediction_service = PredictionService()
